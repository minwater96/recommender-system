{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# NCF using Implicit Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, random, os\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds to make your results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEEDS RESET\n"
     ]
    }
   ],
   "source": [
    "# 매번 모델링을 할 때마다 동일한 결과를 얻으려면 아래 코드를 실행해야 함.\n",
    "\n",
    "def reset_seeds(reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")\n",
    "\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.compat.v1.set_random_seed(3)\n",
    "#    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # for GPU\n",
    "    print(\"RANDOM SEEDS RESET\") \n",
    "   \n",
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'binary_ratings.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 도서판매 트랜잭션을 Negative Sampling을 통해 Implicit 학습/평가 데이터로 변환한 데이터\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train, test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary_ratings.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train\u001b[38;5;241m.\u001b[39mshape,test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniforge3/envs/moontorch/lib/python3.8/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/moontorch/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'binary_ratings.pkl'"
     ]
    }
   ],
   "source": [
    "# 도서판매 트랜잭션을 Negative Sampling을 통해 Implicit 학습/평가 데이터로 변환한 데이터\n",
    "train, test = pd.read_pickle('binary_ratings.pkl')\n",
    "\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack layers from input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable 초기화 \n",
    "K = 8                      # Latent factor 수 \n",
    "M = train.USER.max() + 1   # Number of users\n",
    "N = train.ITEM.max() + 1   # Number of items\n",
    "\n",
    "M, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "user = keras.Input(shape=(1, ))                         \n",
    "item = keras.Input(shape=(1, ))                      \n",
    "\n",
    "# Embedding layer\n",
    "MF_Embedding_User = keras.layers.Embedding(M, K)(user)          \n",
    "MF_Embedding_Item = keras.layers.Embedding(N, K)(item)       \n",
    "\n",
    "MLP_Embedding_User = keras.layers.Embedding(M, 8)(user)  # 8 => NCF 논문 구현체 참고\n",
    "MLP_Embedding_Item = keras.layers.Embedding(N, 8)(item)\n",
    "\n",
    "# GMF part\n",
    "user_latent = keras.layers.Flatten()(MF_Embedding_User)\n",
    "item_latent = keras.layers.Flatten()(MF_Embedding_Item)\n",
    "\n",
    "gmf_output = keras.layers.Multiply()([user_latent, item_latent]) # element-wise product\n",
    "\n",
    "# MLP part \n",
    "user_latent = keras.layers.Flatten()(MLP_Embedding_User)\n",
    "item_latent = keras.layers.Flatten()(MLP_Embedding_Item)\n",
    "\n",
    "x = keras.layers.Concatenate()([user_latent, item_latent])\n",
    "x = keras.layers.Dense(16, activation='elu')(x)  # 최신 activation 함수로 변경\n",
    "x = keras.layers.Dense(8, activation='elu')(x)\n",
    "mlp_output = keras.layers.Dense(4, activation='elu')(x)\n",
    "\n",
    "# Concatenate MF and MLP parts\n",
    "x = keras.layers.Concatenate()([gmf_output, mlp_output])\n",
    "x = keras.layers.Dropout(0.3)(x)   # 과대적합을 줄이기 위해 Dropout 추가\n",
    "\n",
    "# Final prediction layer\n",
    "output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=[user, item], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize & visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연결 그래프 시각화\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"BT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the optimizer and the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, optimizer, metrics 설정\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',                  # 이진분류를 위한 손실함수\n",
    "    optimizer=keras.optimizers.legacy.RMSprop(lr=1e-3), # 옵티마이저 변경\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set learning conditions & fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    x=[train.USER, train.ITEM],\n",
    "    y=train.RATING,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256, \n",
    "    epochs=20, \n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)],\n",
    "    shuffle=False,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize training history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE\n",
    "\n",
    "plt.plot(hist.history['loss'], label=\"train\")\n",
    "plt.plot(hist.history['val_loss'], label=\"valid\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 rating(0~1) 빈도 도식화\n",
    "plt.hist(model.predict([test.USER, test.ITEM]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make top-K recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10        # 추천 아이템 갯수\n",
    "test_users = 100  # 추천 대상자 수\n",
    "\n",
    "# 예측을 위해 아이템수만큼 사용자 ID를 복제하는 과정\n",
    "target_users = []\n",
    "target_items = []\n",
    "for u in np.sort(test.USER.unique()[:test_users]):\n",
    "    for i in test.ITEM.unique():\n",
    "        target_users.append(u)   \n",
    "        target_items.append(i)\n",
    "target_users = np.array(target_users)      \n",
    "target_items = np.array(target_items)    \n",
    "\n",
    "# 예측 스코어를 얻고 평가를 위한 데이터프레임 형식으로 변환하는 과정\n",
    "pred_scores = model.predict([target_users, target_items]).flatten()\n",
    "recommendations = (pd.DataFrame({'USER':target_users, 'ITEM':target_items, 'SCORE':pred_scores})\n",
    "                   .sort_values(by=['USER','SCORE'], ascending=False)\n",
    "                   .groupby('USER')\n",
    "                   .head(top_k))\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the recommendation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit List\n",
    "pd.merge(recommendations, test, on=['USER','ITEM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS Recommender 패키지에서 제공하는 추천시스템 평가함수\n",
    "from msr.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "args = [test, recommendations]\n",
    "kwargs = dict(col_user='USER', \n",
    "              col_item='ITEM', \n",
    "              col_rating='RATING', \n",
    "              col_prediction='SCORE', \n",
    "              relevancy_method='top_k', \n",
    "              k=10)\n",
    "\n",
    "eval_map = map_at_k(*args, **kwargs)\n",
    "eval_ndcg = ndcg_at_k(*args, **kwargs)\n",
    "eval_precision = precision_at_k(*args, **kwargs)\n",
    "eval_recall = recall_at_k(*args, **kwargs)\n",
    "\n",
    "print(f\"Model: NCF\",\n",
    "      f\"Precision@{top_k}:\\t {eval_precision:f}\",\n",
    "      f\"Recall@{top_k}:\\t {eval_recall:f}\", \n",
    "      f\"MAP@{top_k}:\\t\\t {eval_map:f}\",\n",
    "      f\"NDCG@{top_k}:\\t {eval_ndcg:f}\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moontorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
