{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# AutoRec\n",
    "     # 참고: https://github.com/supkoon/AutoRec-tf/blob/master/AutoRec.py\n",
    "             https://changiusk.github.io/papers/autorec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model architecture:\n",
    "<img align='left' src='/Users/kimminsu/Desktop/AI,BIGDATA CLASS/Recommender System/image/autorec_architecture.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss:\n",
    "<img align='left' src='/Users/kimminsu/Desktop/AI,BIGDATA CLASS/Recommender System/image/autorec_loss.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "import pickle, random, os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "\n",
    "kind = 'I'             # I-AutoRec\n",
    "dimension = 50         # number of nodes in bottleneck hidden layer\n",
    "test_size = 0.2        # test_proportion of datasets\n",
    "epochs = 500\n",
    "batch_size = 512\n",
    "reg = 0.0005           # regularization for encoder & decoder\n",
    "learner = 'rmsprop'       # optimizer\n",
    "learning_rate = 0.0001    \n",
    "patience = 10          # earlystopping patience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m movielens_data_file_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://files.grouplens.org/datasets/movielens/ml-latest-small.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m movielens_zipped_file \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/kimminsu/Desktop/AI,BIGDATA CLASS/Recommender System/data\u001b[39m\u001b[38;5;124m\"\u001b[39m, movielens_data_file_url, extract\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m keras_datasets_path \u001b[38;5;241m=\u001b[39m Path(movielens_zipped_file)\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m movielens_dir \u001b[38;5;241m=\u001b[39m keras_datasets_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml-latest-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/AI,BIGDATA CLASS/Recommender System/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tfll_keras_version\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/AI,BIGDATA CLASS/Recommender System/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tfll_keras_version\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 182 (1474 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/AI,BIGDATA CLASS/Recommender System/venv/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tfll_keras_version\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "movielens_data_file_url = \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "movielens_zipped_file = tf.keras.utils.get_file(\n",
    "    \"/Users/kimminsu/Desktop/AI,BIGDATA CLASS/Recommender System/data\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\")as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1500)  # 기본값보다 높은 값으로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movielens_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mdataloader\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# (args) test_size: 테스트 세트 비율\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmovielens_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mratings.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mdataloader\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mdataloader\u001b[39;00m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# (args) test_size: 테스트 세트 비율\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_size, path \u001b[38;5;241m=\u001b[39m \u001b[43mmovielens_dir\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mratings.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_size \u001b[38;5;241m=\u001b[39m test_size\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mratings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movielens_dir' is not defined"
     ]
    }
   ],
   "source": [
    "class dataloader():\n",
    "    # (args) test_size: 테스트 세트 비율\n",
    "    def __init__(self, test_size, path = movielens_dir / \"ratings.csv\"):\n",
    "        self.test_size = test_size\n",
    "        self.ratings_df = pd.read_csv(path)\n",
    "        self.ratings_df.columns = [\"userId\",\"movieId\",\"rating\",\"timestamp\"]\n",
    "        self.num_user = len(self.ratings_df.userId.unique())\n",
    "        self.num_item = len(self.ratings_df.movieId.unique())\n",
    "        \n",
    "    # for U-AutoRec\n",
    "    def make_user_autorec_input(self):\n",
    "        user_item_df = self.ratings_df.pivot_table(index=\"userId\", columns=\"movieId\", values=\"rating\")\n",
    "        user_item_df.fillna(0,inplace=True)\n",
    "        user_item_df = np.array(user_item_df)\n",
    "        train_df, test_df = train_test_split(user_item_df, test_size =self.test_size)\n",
    "        return train_df, test_df\n",
    "\n",
    "    # for I-AutoRec\n",
    "    def make_item_autorec_input(self):\n",
    "        item_user_df = self.ratings_df.pivot_table(index=\"movieId\", columns=\"userId\", values=\"rating\")\n",
    "        item_user_df.fillna(0,inplace=True)\n",
    "        item_user_df = np.array(item_user_df)\n",
    "        train_df, test_df = train_test_split(item_user_df, test_size =self.test_size)\n",
    "        return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    }
   ],
   "source": [
    "dataloader = dataloader(test_size)\n",
    "if kind == 'U': # for U-AutoRec\n",
    "    train_data, test_data = dataloader.make_user_autorec_input()\n",
    "    num_features = dataloader.num_item\n",
    "else:           # for I-AutoRec\n",
    "    train_data, test_data = dataloader.make_item_autorec_input()\n",
    "    num_features = dataloader.num_user\n",
    "\n",
    "print(num_features)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack layers from input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = x = keras.Input(shape=(num_features,), name='UserRating')\n",
    "x = keras.layers.Dense(dimension, activation='relu', kernel_regularizer=keras.regularizers.L2(reg), name='LatentSpace')(x)\n",
    "output_layer = keras.layers.Dense(num_features, activation='linear', kernel_regularizer=keras.regularizers.L2(reg), name='UserScorePred')(x)\n",
    "model = keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize & visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " UserRating (InputLayer)     [(None, 610)]             0         \n",
      "                                                                 \n",
      " LatentSpace (Dense)         (None, 50)                30550     \n",
      "                                                                 \n",
      " UserScorePred (Dense)       (None, 610)               31110     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61660 (240.86 KB)\n",
      "Trainable params: 61660 (240.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연결 그래프 시각화\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define customized loss & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse_loss(y_true, y_pred):\n",
    "    # 마스크 : 관측된 데이터에 대해서는 1, 관측되지 않은데이터는 0\n",
    "    mask = y_true != 0 \n",
    "    #기존에 관측되지 않았던 결과에 대해서는 마스킹을 진행하여 Loss 계산\n",
    "    mask_float = tf.cast(mask, tf.float32)\n",
    "    masked_error = tf.reduce_mean(tf.pow(tf.subtract(mask_float * y_pred,y_true),2))\n",
    "    return masked_error\n",
    "\n",
    "def masked_rmse_clip(y_true, y_pred):\n",
    "    mask = y_true != 0 \n",
    "    # 예측값이 1 ~ 5가 되도록 조정\n",
    "    y_pred = tf.clip_by_value(y_pred, 1, 5)\n",
    "    mask_float = tf.cast(mask, tf.float32)\n",
    "    masked_error = tf.reduce_mean(tf.pow(tf.subtract(mask_float * y_pred,y_true),2))\n",
    "    return tf.sqrt(masked_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set optimizer, learning rate, loss & metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 설정한 옵티마이저와 학습율을 반영하여 compile 수행\n",
    "if learner.lower() == \"adagrad\":\n",
    "    model.compile(optimizer=keras.optimizers.legacy.Adagrad(learning_rate=learning_rate), loss=masked_mse_loss,\n",
    "                  metrics=[masked_rmse_clip])\n",
    "elif learner.lower() == \"rmsprop\":\n",
    "    model.compile(optimizer=keras.optimizers.legacy.RMSprop(learning_rate=learning_rate), loss=masked_mse_loss,\n",
    "                  metrics=[masked_rmse_clip])\n",
    "elif learner.lower() == \"adam\":\n",
    "    model.compile(optimizer=keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss=masked_mse_loss,\n",
    "                  metrics=[masked_rmse_clip])\n",
    "else:\n",
    "    model.compile(optimizer=keras.optimizers.legacy.SGD(learning_rate=learning_rate), loss=masked_mse_loss,\n",
    "                  metrics=[masked_rmse_clip])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set learning conditions & fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3148 - masked_rmse_clip: 0.3528 - val_loss: 0.3113 - val_masked_rmse_clip: 0.3522\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3048 - masked_rmse_clip: 0.3551 - val_loss: 0.3023 - val_masked_rmse_clip: 0.3512\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2955 - masked_rmse_clip: 0.3528 - val_loss: 0.2925 - val_masked_rmse_clip: 0.3493\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2852 - masked_rmse_clip: 0.3487 - val_loss: 0.2816 - val_masked_rmse_clip: 0.3461\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2737 - masked_rmse_clip: 0.3415 - val_loss: 0.2693 - val_masked_rmse_clip: 0.3414\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2609 - masked_rmse_clip: 0.3350 - val_loss: 0.2557 - val_masked_rmse_clip: 0.3349\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2470 - masked_rmse_clip: 0.3322 - val_loss: 0.2413 - val_masked_rmse_clip: 0.3271\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2332 - masked_rmse_clip: 0.3220 - val_loss: 0.2284 - val_masked_rmse_clip: 0.3188\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2207 - masked_rmse_clip: 0.3148 - val_loss: 0.2167 - val_masked_rmse_clip: 0.3104\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2093 - masked_rmse_clip: 0.3064 - val_loss: 0.2062 - val_masked_rmse_clip: 0.3025\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1993 - masked_rmse_clip: 0.2968 - val_loss: 0.1971 - val_masked_rmse_clip: 0.2959\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1907 - masked_rmse_clip: 0.2903 - val_loss: 0.1891 - val_masked_rmse_clip: 0.2889\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1831 - masked_rmse_clip: 0.2832 - val_loss: 0.1820 - val_masked_rmse_clip: 0.2832\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1764 - masked_rmse_clip: 0.2810 - val_loss: 0.1756 - val_masked_rmse_clip: 0.2779\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1703 - masked_rmse_clip: 0.2739 - val_loss: 0.1698 - val_masked_rmse_clip: 0.2731\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1649 - masked_rmse_clip: 0.2717 - val_loss: 0.1643 - val_masked_rmse_clip: 0.2700\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1602 - masked_rmse_clip: 0.2682 - val_loss: 0.1601 - val_masked_rmse_clip: 0.2662\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1560 - masked_rmse_clip: 0.2630 - val_loss: 0.1559 - val_masked_rmse_clip: 0.2630\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1519 - masked_rmse_clip: 0.2592 - val_loss: 0.1518 - val_masked_rmse_clip: 0.2599\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1480 - masked_rmse_clip: 0.2563 - val_loss: 0.1478 - val_masked_rmse_clip: 0.2576\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1442 - masked_rmse_clip: 0.2555 - val_loss: 0.1440 - val_masked_rmse_clip: 0.2546\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1406 - masked_rmse_clip: 0.2531 - val_loss: 0.1407 - val_masked_rmse_clip: 0.2512\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1372 - masked_rmse_clip: 0.2494 - val_loss: 0.1372 - val_masked_rmse_clip: 0.2494\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1339 - masked_rmse_clip: 0.2479 - val_loss: 0.1341 - val_masked_rmse_clip: 0.2466\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1308 - masked_rmse_clip: 0.2441 - val_loss: 0.1310 - val_masked_rmse_clip: 0.2446\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1277 - masked_rmse_clip: 0.2422 - val_loss: 0.1280 - val_masked_rmse_clip: 0.2422\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1248 - masked_rmse_clip: 0.2391 - val_loss: 0.1250 - val_masked_rmse_clip: 0.2405\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1218 - masked_rmse_clip: 0.2372 - val_loss: 0.1223 - val_masked_rmse_clip: 0.2377\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1190 - masked_rmse_clip: 0.2352 - val_loss: 0.1194 - val_masked_rmse_clip: 0.2358\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1162 - masked_rmse_clip: 0.2324 - val_loss: 0.1168 - val_masked_rmse_clip: 0.2332\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1135 - masked_rmse_clip: 0.2295 - val_loss: 0.1143 - val_masked_rmse_clip: 0.2316\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1110 - masked_rmse_clip: 0.2287 - val_loss: 0.1121 - val_masked_rmse_clip: 0.2289\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1086 - masked_rmse_clip: 0.2244 - val_loss: 0.1097 - val_masked_rmse_clip: 0.2276\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1063 - masked_rmse_clip: 0.2224 - val_loss: 0.1077 - val_masked_rmse_clip: 0.2253\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1040 - masked_rmse_clip: 0.2218 - val_loss: 0.1054 - val_masked_rmse_clip: 0.2238\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1019 - masked_rmse_clip: 0.2194 - val_loss: 0.1032 - val_masked_rmse_clip: 0.2223\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0997 - masked_rmse_clip: 0.2187 - val_loss: 0.1013 - val_masked_rmse_clip: 0.2205\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0977 - masked_rmse_clip: 0.2177 - val_loss: 0.0993 - val_masked_rmse_clip: 0.2193\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0959 - masked_rmse_clip: 0.2163 - val_loss: 0.0977 - val_masked_rmse_clip: 0.2174\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0941 - masked_rmse_clip: 0.2134 - val_loss: 0.0959 - val_masked_rmse_clip: 0.2161\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0923 - masked_rmse_clip: 0.2117 - val_loss: 0.0943 - val_masked_rmse_clip: 0.2147\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0907 - masked_rmse_clip: 0.2107 - val_loss: 0.0926 - val_masked_rmse_clip: 0.2137\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0891 - masked_rmse_clip: 0.2093 - val_loss: 0.0912 - val_masked_rmse_clip: 0.2121\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0875 - masked_rmse_clip: 0.2083 - val_loss: 0.0894 - val_masked_rmse_clip: 0.2113\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0860 - masked_rmse_clip: 0.2066 - val_loss: 0.0883 - val_masked_rmse_clip: 0.2098\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0845 - masked_rmse_clip: 0.2055 - val_loss: 0.0866 - val_masked_rmse_clip: 0.2090\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0831 - masked_rmse_clip: 0.2056 - val_loss: 0.0854 - val_masked_rmse_clip: 0.2077\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0818 - masked_rmse_clip: 0.2030 - val_loss: 0.0838 - val_masked_rmse_clip: 0.2071\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0805 - masked_rmse_clip: 0.2026 - val_loss: 0.0826 - val_masked_rmse_clip: 0.2060\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0793 - masked_rmse_clip: 0.2007 - val_loss: 0.0815 - val_masked_rmse_clip: 0.2051\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0781 - masked_rmse_clip: 0.2000 - val_loss: 0.0803 - val_masked_rmse_clip: 0.2042\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0769 - masked_rmse_clip: 0.1986 - val_loss: 0.0790 - val_masked_rmse_clip: 0.2036\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0758 - masked_rmse_clip: 0.1989 - val_loss: 0.0780 - val_masked_rmse_clip: 0.2024\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0747 - masked_rmse_clip: 0.1977 - val_loss: 0.0771 - val_masked_rmse_clip: 0.2015\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0737 - masked_rmse_clip: 0.1965 - val_loss: 0.0760 - val_masked_rmse_clip: 0.2009\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0727 - masked_rmse_clip: 0.1961 - val_loss: 0.0750 - val_masked_rmse_clip: 0.2001\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0717 - masked_rmse_clip: 0.1962 - val_loss: 0.0739 - val_masked_rmse_clip: 0.1998\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0708 - masked_rmse_clip: 0.1950 - val_loss: 0.0730 - val_masked_rmse_clip: 0.1990\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0700 - masked_rmse_clip: 0.1937 - val_loss: 0.0722 - val_masked_rmse_clip: 0.1984\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0691 - masked_rmse_clip: 0.1944 - val_loss: 0.0713 - val_masked_rmse_clip: 0.1979\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0683 - masked_rmse_clip: 0.1935 - val_loss: 0.0706 - val_masked_rmse_clip: 0.1971\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0675 - masked_rmse_clip: 0.1915 - val_loss: 0.0700 - val_masked_rmse_clip: 0.1964\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0668 - masked_rmse_clip: 0.1920 - val_loss: 0.0692 - val_masked_rmse_clip: 0.1959\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0661 - masked_rmse_clip: 0.1908 - val_loss: 0.0685 - val_masked_rmse_clip: 0.1954\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0654 - masked_rmse_clip: 0.1898 - val_loss: 0.0678 - val_masked_rmse_clip: 0.1948\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0647 - masked_rmse_clip: 0.1891 - val_loss: 0.0671 - val_masked_rmse_clip: 0.1942\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0641 - masked_rmse_clip: 0.1893 - val_loss: 0.0664 - val_masked_rmse_clip: 0.1938\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0634 - masked_rmse_clip: 0.1894 - val_loss: 0.0657 - val_masked_rmse_clip: 0.1935\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0628 - masked_rmse_clip: 0.1877 - val_loss: 0.0652 - val_masked_rmse_clip: 0.1928\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0623 - masked_rmse_clip: 0.1877 - val_loss: 0.0645 - val_masked_rmse_clip: 0.1927\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0617 - masked_rmse_clip: 0.1878 - val_loss: 0.0640 - val_masked_rmse_clip: 0.1923\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0612 - masked_rmse_clip: 0.1866 - val_loss: 0.0636 - val_masked_rmse_clip: 0.1917\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0607 - masked_rmse_clip: 0.1862 - val_loss: 0.0632 - val_masked_rmse_clip: 0.1911\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0603 - masked_rmse_clip: 0.1853 - val_loss: 0.0626 - val_masked_rmse_clip: 0.1908\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0598 - masked_rmse_clip: 0.1855 - val_loss: 0.0621 - val_masked_rmse_clip: 0.1903\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0593 - masked_rmse_clip: 0.1852 - val_loss: 0.0618 - val_masked_rmse_clip: 0.1899\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0589 - masked_rmse_clip: 0.1855 - val_loss: 0.0613 - val_masked_rmse_clip: 0.1897\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0584 - masked_rmse_clip: 0.1846 - val_loss: 0.0610 - val_masked_rmse_clip: 0.1892\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0581 - masked_rmse_clip: 0.1842 - val_loss: 0.0604 - val_masked_rmse_clip: 0.1890\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0577 - masked_rmse_clip: 0.1844 - val_loss: 0.0601 - val_masked_rmse_clip: 0.1887\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0573 - masked_rmse_clip: 0.1836 - val_loss: 0.0599 - val_masked_rmse_clip: 0.1882\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0570 - masked_rmse_clip: 0.1829 - val_loss: 0.0594 - val_masked_rmse_clip: 0.1882\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0566 - masked_rmse_clip: 0.1836 - val_loss: 0.0590 - val_masked_rmse_clip: 0.1877\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0563 - masked_rmse_clip: 0.1816 - val_loss: 0.0588 - val_masked_rmse_clip: 0.1874\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0560 - masked_rmse_clip: 0.1810 - val_loss: 0.0584 - val_masked_rmse_clip: 0.1871\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0557 - masked_rmse_clip: 0.1811 - val_loss: 0.0580 - val_masked_rmse_clip: 0.1870\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0553 - masked_rmse_clip: 0.1802 - val_loss: 0.0578 - val_masked_rmse_clip: 0.1865\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0551 - masked_rmse_clip: 0.1808 - val_loss: 0.0575 - val_masked_rmse_clip: 0.1863\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0548 - masked_rmse_clip: 0.1810 - val_loss: 0.0572 - val_masked_rmse_clip: 0.1862\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0545 - masked_rmse_clip: 0.1805 - val_loss: 0.0570 - val_masked_rmse_clip: 0.1858\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0543 - masked_rmse_clip: 0.1805 - val_loss: 0.0569 - val_masked_rmse_clip: 0.1854\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0540 - masked_rmse_clip: 0.1787 - val_loss: 0.0565 - val_masked_rmse_clip: 0.1852\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0537 - masked_rmse_clip: 0.1804 - val_loss: 0.0562 - val_masked_rmse_clip: 0.1852\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0535 - masked_rmse_clip: 0.1797 - val_loss: 0.0562 - val_masked_rmse_clip: 0.1847\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0533 - masked_rmse_clip: 0.1792 - val_loss: 0.0557 - val_masked_rmse_clip: 0.1844\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0531 - masked_rmse_clip: 0.1794 - val_loss: 0.0555 - val_masked_rmse_clip: 0.1843\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0528 - masked_rmse_clip: 0.1784 - val_loss: 0.0552 - val_masked_rmse_clip: 0.1843\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0526 - masked_rmse_clip: 0.1785 - val_loss: 0.0551 - val_masked_rmse_clip: 0.1838\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0524 - masked_rmse_clip: 0.1786 - val_loss: 0.0549 - val_masked_rmse_clip: 0.1836\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0522 - masked_rmse_clip: 0.1781 - val_loss: 0.0548 - val_masked_rmse_clip: 0.1833\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0520 - masked_rmse_clip: 0.1786 - val_loss: 0.0544 - val_masked_rmse_clip: 0.1833\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0518 - masked_rmse_clip: 0.1776 - val_loss: 0.0542 - val_masked_rmse_clip: 0.1829\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0517 - masked_rmse_clip: 0.1771 - val_loss: 0.0542 - val_masked_rmse_clip: 0.1826\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0515 - masked_rmse_clip: 0.1779 - val_loss: 0.0538 - val_masked_rmse_clip: 0.1825\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0513 - masked_rmse_clip: 0.1775 - val_loss: 0.0538 - val_masked_rmse_clip: 0.1822\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0512 - masked_rmse_clip: 0.1767 - val_loss: 0.0536 - val_masked_rmse_clip: 0.1822\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0510 - masked_rmse_clip: 0.1773 - val_loss: 0.0534 - val_masked_rmse_clip: 0.1820\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0508 - masked_rmse_clip: 0.1759 - val_loss: 0.0533 - val_masked_rmse_clip: 0.1817\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0507 - masked_rmse_clip: 0.1761 - val_loss: 0.0530 - val_masked_rmse_clip: 0.1816\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0505 - masked_rmse_clip: 0.1767 - val_loss: 0.0528 - val_masked_rmse_clip: 0.1815\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0504 - masked_rmse_clip: 0.1766 - val_loss: 0.0528 - val_masked_rmse_clip: 0.1811\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0502 - masked_rmse_clip: 0.1760 - val_loss: 0.0528 - val_masked_rmse_clip: 0.1808\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0501 - masked_rmse_clip: 0.1759 - val_loss: 0.0525 - val_masked_rmse_clip: 0.1807\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0499 - masked_rmse_clip: 0.1744 - val_loss: 0.0523 - val_masked_rmse_clip: 0.1806\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0498 - masked_rmse_clip: 0.1746 - val_loss: 0.0523 - val_masked_rmse_clip: 0.1803\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0497 - masked_rmse_clip: 0.1745 - val_loss: 0.0519 - val_masked_rmse_clip: 0.1802\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0495 - masked_rmse_clip: 0.1743 - val_loss: 0.0519 - val_masked_rmse_clip: 0.1800\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0494 - masked_rmse_clip: 0.1743 - val_loss: 0.0517 - val_masked_rmse_clip: 0.1799\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0493 - masked_rmse_clip: 0.1744 - val_loss: 0.0517 - val_masked_rmse_clip: 0.1796\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0491 - masked_rmse_clip: 0.1750 - val_loss: 0.0516 - val_masked_rmse_clip: 0.1794\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0490 - masked_rmse_clip: 0.1740 - val_loss: 0.0512 - val_masked_rmse_clip: 0.1794\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0489 - masked_rmse_clip: 0.1731 - val_loss: 0.0511 - val_masked_rmse_clip: 0.1792\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0488 - masked_rmse_clip: 0.1736 - val_loss: 0.0511 - val_masked_rmse_clip: 0.1789\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0487 - masked_rmse_clip: 0.1728 - val_loss: 0.0511 - val_masked_rmse_clip: 0.1788\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0485 - masked_rmse_clip: 0.1731 - val_loss: 0.0508 - val_masked_rmse_clip: 0.1787\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0484 - masked_rmse_clip: 0.1732 - val_loss: 0.0506 - val_masked_rmse_clip: 0.1787\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0483 - masked_rmse_clip: 0.1728 - val_loss: 0.0508 - val_masked_rmse_clip: 0.1784\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0482 - masked_rmse_clip: 0.1722 - val_loss: 0.0505 - val_masked_rmse_clip: 0.1783\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0481 - masked_rmse_clip: 0.1723 - val_loss: 0.0503 - val_masked_rmse_clip: 0.1781\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0480 - masked_rmse_clip: 0.1720 - val_loss: 0.0503 - val_masked_rmse_clip: 0.1779\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0479 - masked_rmse_clip: 0.1718 - val_loss: 0.0502 - val_masked_rmse_clip: 0.1777\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0478 - masked_rmse_clip: 0.1725 - val_loss: 0.0500 - val_masked_rmse_clip: 0.1777\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0477 - masked_rmse_clip: 0.1716 - val_loss: 0.0499 - val_masked_rmse_clip: 0.1776\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0476 - masked_rmse_clip: 0.1725 - val_loss: 0.0497 - val_masked_rmse_clip: 0.1775\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - masked_rmse_clip: 0.1724 - val_loss: 0.0498 - val_masked_rmse_clip: 0.1772\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0474 - masked_rmse_clip: 0.1721 - val_loss: 0.0497 - val_masked_rmse_clip: 0.1771\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0473 - masked_rmse_clip: 0.1722 - val_loss: 0.0495 - val_masked_rmse_clip: 0.1770\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0472 - masked_rmse_clip: 0.1705 - val_loss: 0.0495 - val_masked_rmse_clip: 0.1768\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0471 - masked_rmse_clip: 0.1707 - val_loss: 0.0494 - val_masked_rmse_clip: 0.1766\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0470 - masked_rmse_clip: 0.1711 - val_loss: 0.0492 - val_masked_rmse_clip: 0.1765\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0469 - masked_rmse_clip: 0.1700 - val_loss: 0.0491 - val_masked_rmse_clip: 0.1764\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0468 - masked_rmse_clip: 0.1704 - val_loss: 0.0491 - val_masked_rmse_clip: 0.1762\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0468 - masked_rmse_clip: 0.1701 - val_loss: 0.0490 - val_masked_rmse_clip: 0.1761\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0467 - masked_rmse_clip: 0.1713 - val_loss: 0.0489 - val_masked_rmse_clip: 0.1759\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0466 - masked_rmse_clip: 0.1721 - val_loss: 0.0487 - val_masked_rmse_clip: 0.1759\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0465 - masked_rmse_clip: 0.1703 - val_loss: 0.0486 - val_masked_rmse_clip: 0.1757\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0464 - masked_rmse_clip: 0.1704 - val_loss: 0.0487 - val_masked_rmse_clip: 0.1755\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0463 - masked_rmse_clip: 0.1706 - val_loss: 0.0485 - val_masked_rmse_clip: 0.1755\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0462 - masked_rmse_clip: 0.1701 - val_loss: 0.0485 - val_masked_rmse_clip: 0.1752\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0462 - masked_rmse_clip: 0.1702 - val_loss: 0.0483 - val_masked_rmse_clip: 0.1751\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0461 - masked_rmse_clip: 0.1697 - val_loss: 0.0482 - val_masked_rmse_clip: 0.1751\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0460 - masked_rmse_clip: 0.1697 - val_loss: 0.0481 - val_masked_rmse_clip: 0.1749\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0459 - masked_rmse_clip: 0.1695 - val_loss: 0.0480 - val_masked_rmse_clip: 0.1748\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0458 - masked_rmse_clip: 0.1698 - val_loss: 0.0483 - val_masked_rmse_clip: 0.1747\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0458 - masked_rmse_clip: 0.1692 - val_loss: 0.0479 - val_masked_rmse_clip: 0.1746\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0457 - masked_rmse_clip: 0.1697 - val_loss: 0.0479 - val_masked_rmse_clip: 0.1743\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0456 - masked_rmse_clip: 0.1686 - val_loss: 0.0477 - val_masked_rmse_clip: 0.1742\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - masked_rmse_clip: 0.1700 - val_loss: 0.0476 - val_masked_rmse_clip: 0.1741\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0455 - masked_rmse_clip: 0.1687 - val_loss: 0.0475 - val_masked_rmse_clip: 0.1740\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0454 - masked_rmse_clip: 0.1696 - val_loss: 0.0475 - val_masked_rmse_clip: 0.1738\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0453 - masked_rmse_clip: 0.1687 - val_loss: 0.0474 - val_masked_rmse_clip: 0.1738\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - masked_rmse_clip: 0.1689 - val_loss: 0.0475 - val_masked_rmse_clip: 0.1736\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0452 - masked_rmse_clip: 0.1687 - val_loss: 0.0474 - val_masked_rmse_clip: 0.1734\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0451 - masked_rmse_clip: 0.1683 - val_loss: 0.0472 - val_masked_rmse_clip: 0.1733\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - masked_rmse_clip: 0.1677 - val_loss: 0.0471 - val_masked_rmse_clip: 0.1733\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0450 - masked_rmse_clip: 0.1675 - val_loss: 0.0471 - val_masked_rmse_clip: 0.1731\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0449 - masked_rmse_clip: 0.1679 - val_loss: 0.0469 - val_masked_rmse_clip: 0.1730\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0448 - masked_rmse_clip: 0.1680 - val_loss: 0.0468 - val_masked_rmse_clip: 0.1729\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0447 - masked_rmse_clip: 0.1678 - val_loss: 0.0467 - val_masked_rmse_clip: 0.1729\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0447 - masked_rmse_clip: 0.1678 - val_loss: 0.0468 - val_masked_rmse_clip: 0.1726\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0446 - masked_rmse_clip: 0.1674 - val_loss: 0.0467 - val_masked_rmse_clip: 0.1727\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - masked_rmse_clip: 0.1669 - val_loss: 0.0466 - val_masked_rmse_clip: 0.1725\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0445 - masked_rmse_clip: 0.1667 - val_loss: 0.0465 - val_masked_rmse_clip: 0.1723\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0444 - masked_rmse_clip: 0.1667 - val_loss: 0.0465 - val_masked_rmse_clip: 0.1722\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - masked_rmse_clip: 0.1662 - val_loss: 0.0464 - val_masked_rmse_clip: 0.1720\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0443 - masked_rmse_clip: 0.1672 - val_loss: 0.0463 - val_masked_rmse_clip: 0.1720\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0442 - masked_rmse_clip: 0.1666 - val_loss: 0.0462 - val_masked_rmse_clip: 0.1718\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - masked_rmse_clip: 0.1670 - val_loss: 0.0463 - val_masked_rmse_clip: 0.1717\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0441 - masked_rmse_clip: 0.1667 - val_loss: 0.0462 - val_masked_rmse_clip: 0.1716\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0440 - masked_rmse_clip: 0.1664 - val_loss: 0.0461 - val_masked_rmse_clip: 0.1714\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - masked_rmse_clip: 0.1658 - val_loss: 0.0459 - val_masked_rmse_clip: 0.1714\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0439 - masked_rmse_clip: 0.1663 - val_loss: 0.0460 - val_masked_rmse_clip: 0.1713\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0438 - masked_rmse_clip: 0.1658 - val_loss: 0.0457 - val_masked_rmse_clip: 0.1712\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - masked_rmse_clip: 0.1656 - val_loss: 0.0459 - val_masked_rmse_clip: 0.1710\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0437 - masked_rmse_clip: 0.1657 - val_loss: 0.0456 - val_masked_rmse_clip: 0.1709\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0436 - masked_rmse_clip: 0.1656 - val_loss: 0.0455 - val_masked_rmse_clip: 0.1708\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - masked_rmse_clip: 0.1647 - val_loss: 0.0456 - val_masked_rmse_clip: 0.1707\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0435 - masked_rmse_clip: 0.1649 - val_loss: 0.0455 - val_masked_rmse_clip: 0.1706\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0434 - masked_rmse_clip: 0.1660 - val_loss: 0.0453 - val_masked_rmse_clip: 0.1705\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - masked_rmse_clip: 0.1657 - val_loss: 0.0452 - val_masked_rmse_clip: 0.1704\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0433 - masked_rmse_clip: 0.1655 - val_loss: 0.0452 - val_masked_rmse_clip: 0.1702\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - masked_rmse_clip: 0.1653 - val_loss: 0.0454 - val_masked_rmse_clip: 0.1701\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0432 - masked_rmse_clip: 0.1654 - val_loss: 0.0451 - val_masked_rmse_clip: 0.1700\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0431 - masked_rmse_clip: 0.1641 - val_loss: 0.0451 - val_masked_rmse_clip: 0.1699\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - masked_rmse_clip: 0.1650 - val_loss: 0.0450 - val_masked_rmse_clip: 0.1698\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0430 - masked_rmse_clip: 0.1644 - val_loss: 0.0449 - val_masked_rmse_clip: 0.1697\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0429 - masked_rmse_clip: 0.1645 - val_loss: 0.0448 - val_masked_rmse_clip: 0.1698\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0429 - masked_rmse_clip: 0.1643 - val_loss: 0.0448 - val_masked_rmse_clip: 0.1695\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0428 - masked_rmse_clip: 0.1648 - val_loss: 0.0448 - val_masked_rmse_clip: 0.1694\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - masked_rmse_clip: 0.1642 - val_loss: 0.0446 - val_masked_rmse_clip: 0.1693\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0427 - masked_rmse_clip: 0.1639 - val_loss: 0.0445 - val_masked_rmse_clip: 0.1692\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - masked_rmse_clip: 0.1631 - val_loss: 0.0445 - val_masked_rmse_clip: 0.1690\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0426 - masked_rmse_clip: 0.1636 - val_loss: 0.0445 - val_masked_rmse_clip: 0.1689\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0425 - masked_rmse_clip: 0.1636 - val_loss: 0.0444 - val_masked_rmse_clip: 0.1688\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - masked_rmse_clip: 0.1637 - val_loss: 0.0445 - val_masked_rmse_clip: 0.1688\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0424 - masked_rmse_clip: 0.1634 - val_loss: 0.0443 - val_masked_rmse_clip: 0.1686\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0423 - masked_rmse_clip: 0.1634 - val_loss: 0.0443 - val_masked_rmse_clip: 0.1685\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - masked_rmse_clip: 0.1633 - val_loss: 0.0441 - val_masked_rmse_clip: 0.1684\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0422 - masked_rmse_clip: 0.1631 - val_loss: 0.0441 - val_masked_rmse_clip: 0.1683\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - masked_rmse_clip: 0.1642 - val_loss: 0.0440 - val_masked_rmse_clip: 0.1681\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0421 - masked_rmse_clip: 0.1635 - val_loss: 0.0440 - val_masked_rmse_clip: 0.1680\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - masked_rmse_clip: 0.1633 - val_loss: 0.0439 - val_masked_rmse_clip: 0.1680\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0420 - masked_rmse_clip: 0.1631 - val_loss: 0.0438 - val_masked_rmse_clip: 0.1679\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0419 - masked_rmse_clip: 0.1633 - val_loss: 0.0437 - val_masked_rmse_clip: 0.1679\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - masked_rmse_clip: 0.1624 - val_loss: 0.0438 - val_masked_rmse_clip: 0.1677\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0418 - masked_rmse_clip: 0.1625 - val_loss: 0.0436 - val_masked_rmse_clip: 0.1675\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0417 - masked_rmse_clip: 0.1626 - val_loss: 0.0436 - val_masked_rmse_clip: 0.1675\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0417 - masked_rmse_clip: 0.1636 - val_loss: 0.0435 - val_masked_rmse_clip: 0.1674\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - masked_rmse_clip: 0.1626 - val_loss: 0.0436 - val_masked_rmse_clip: 0.1672\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0416 - masked_rmse_clip: 0.1618 - val_loss: 0.0435 - val_masked_rmse_clip: 0.1671\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - masked_rmse_clip: 0.1626 - val_loss: 0.0433 - val_masked_rmse_clip: 0.1672\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0415 - masked_rmse_clip: 0.1617 - val_loss: 0.0433 - val_masked_rmse_clip: 0.1670\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0414 - masked_rmse_clip: 0.1628 - val_loss: 0.0433 - val_masked_rmse_clip: 0.1668\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - masked_rmse_clip: 0.1616 - val_loss: 0.0432 - val_masked_rmse_clip: 0.1667\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0413 - masked_rmse_clip: 0.1606 - val_loss: 0.0432 - val_masked_rmse_clip: 0.1665\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - masked_rmse_clip: 0.1618 - val_loss: 0.0431 - val_masked_rmse_clip: 0.1664\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0412 - masked_rmse_clip: 0.1616 - val_loss: 0.0431 - val_masked_rmse_clip: 0.1663\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - masked_rmse_clip: 0.1609 - val_loss: 0.0430 - val_masked_rmse_clip: 0.1663\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0411 - masked_rmse_clip: 0.1618 - val_loss: 0.0429 - val_masked_rmse_clip: 0.1661\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0410 - masked_rmse_clip: 0.1609 - val_loss: 0.0430 - val_masked_rmse_clip: 0.1661\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - masked_rmse_clip: 0.1603 - val_loss: 0.0429 - val_masked_rmse_clip: 0.1660\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0409 - masked_rmse_clip: 0.1601 - val_loss: 0.0427 - val_masked_rmse_clip: 0.1659\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0408 - masked_rmse_clip: 0.1606 - val_loss: 0.0427 - val_masked_rmse_clip: 0.1657\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0408 - masked_rmse_clip: 0.1610 - val_loss: 0.0426 - val_masked_rmse_clip: 0.1656\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - masked_rmse_clip: 0.1611 - val_loss: 0.0426 - val_masked_rmse_clip: 0.1656\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0407 - masked_rmse_clip: 0.1594 - val_loss: 0.0425 - val_masked_rmse_clip: 0.1655\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - masked_rmse_clip: 0.1612 - val_loss: 0.0424 - val_masked_rmse_clip: 0.1655\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0406 - masked_rmse_clip: 0.1599 - val_loss: 0.0424 - val_masked_rmse_clip: 0.1653\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0405 - masked_rmse_clip: 0.1609 - val_loss: 0.0425 - val_masked_rmse_clip: 0.1652\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - masked_rmse_clip: 0.1600 - val_loss: 0.0422 - val_masked_rmse_clip: 0.1651\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0404 - masked_rmse_clip: 0.1605 - val_loss: 0.0423 - val_masked_rmse_clip: 0.1649\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - masked_rmse_clip: 0.1602 - val_loss: 0.0421 - val_masked_rmse_clip: 0.1649\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0403 - masked_rmse_clip: 0.1607 - val_loss: 0.0422 - val_masked_rmse_clip: 0.1647\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - masked_rmse_clip: 0.1598 - val_loss: 0.0420 - val_masked_rmse_clip: 0.1646\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0402 - masked_rmse_clip: 0.1596 - val_loss: 0.0419 - val_masked_rmse_clip: 0.1645\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - masked_rmse_clip: 0.1594 - val_loss: 0.0419 - val_masked_rmse_clip: 0.1644\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0401 - masked_rmse_clip: 0.1596 - val_loss: 0.0419 - val_masked_rmse_clip: 0.1644\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - masked_rmse_clip: 0.1587 - val_loss: 0.0418 - val_masked_rmse_clip: 0.1643\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0400 - masked_rmse_clip: 0.1595 - val_loss: 0.0418 - val_masked_rmse_clip: 0.1641\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - masked_rmse_clip: 0.1595 - val_loss: 0.0418 - val_masked_rmse_clip: 0.1641\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0399 - masked_rmse_clip: 0.1586 - val_loss: 0.0416 - val_masked_rmse_clip: 0.1640\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0398 - masked_rmse_clip: 0.1590 - val_loss: 0.0416 - val_masked_rmse_clip: 0.1637\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0397 - masked_rmse_clip: 0.1581 - val_loss: 0.0415 - val_masked_rmse_clip: 0.1637\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0397 - masked_rmse_clip: 0.1586 - val_loss: 0.0415 - val_masked_rmse_clip: 0.1636\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - masked_rmse_clip: 0.1606 - val_loss: 0.0414 - val_masked_rmse_clip: 0.1635\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0396 - masked_rmse_clip: 0.1584 - val_loss: 0.0414 - val_masked_rmse_clip: 0.1634\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - masked_rmse_clip: 0.1574 - val_loss: 0.0415 - val_masked_rmse_clip: 0.1634\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0395 - masked_rmse_clip: 0.1579 - val_loss: 0.0413 - val_masked_rmse_clip: 0.1632\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - masked_rmse_clip: 0.1576 - val_loss: 0.0413 - val_masked_rmse_clip: 0.1631\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0394 - masked_rmse_clip: 0.1580 - val_loss: 0.0412 - val_masked_rmse_clip: 0.1629\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - masked_rmse_clip: 0.1590 - val_loss: 0.0411 - val_masked_rmse_clip: 0.1629\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0393 - masked_rmse_clip: 0.1574 - val_loss: 0.0412 - val_masked_rmse_clip: 0.1627\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - masked_rmse_clip: 0.1581 - val_loss: 0.0411 - val_masked_rmse_clip: 0.1626\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0392 - masked_rmse_clip: 0.1572 - val_loss: 0.0409 - val_masked_rmse_clip: 0.1625\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - masked_rmse_clip: 0.1577 - val_loss: 0.0409 - val_masked_rmse_clip: 0.1624\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0391 - masked_rmse_clip: 0.1578 - val_loss: 0.0408 - val_masked_rmse_clip: 0.1623\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - masked_rmse_clip: 0.1568 - val_loss: 0.0407 - val_masked_rmse_clip: 0.1622\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0390 - masked_rmse_clip: 0.1579 - val_loss: 0.0408 - val_masked_rmse_clip: 0.1621\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0389 - masked_rmse_clip: 0.1569 - val_loss: 0.0407 - val_masked_rmse_clip: 0.1620\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0389 - masked_rmse_clip: 0.1571 - val_loss: 0.0406 - val_masked_rmse_clip: 0.1619\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0388 - masked_rmse_clip: 0.1570 - val_loss: 0.0405 - val_masked_rmse_clip: 0.1619\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - masked_rmse_clip: 0.1569 - val_loss: 0.0407 - val_masked_rmse_clip: 0.1618\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - masked_rmse_clip: 0.1568 - val_loss: 0.0404 - val_masked_rmse_clip: 0.1616\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0387 - masked_rmse_clip: 0.1561 - val_loss: 0.0404 - val_masked_rmse_clip: 0.1616\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - masked_rmse_clip: 0.1568 - val_loss: 0.0403 - val_masked_rmse_clip: 0.1614\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0386 - masked_rmse_clip: 0.1567 - val_loss: 0.0403 - val_masked_rmse_clip: 0.1613\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - masked_rmse_clip: 0.1562 - val_loss: 0.0403 - val_masked_rmse_clip: 0.1612\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0385 - masked_rmse_clip: 0.1567 - val_loss: 0.0402 - val_masked_rmse_clip: 0.1611\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - masked_rmse_clip: 0.1561 - val_loss: 0.0402 - val_masked_rmse_clip: 0.1610\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0384 - masked_rmse_clip: 0.1561 - val_loss: 0.0401 - val_masked_rmse_clip: 0.1609\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - masked_rmse_clip: 0.1564 - val_loss: 0.0401 - val_masked_rmse_clip: 0.1608\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0383 - masked_rmse_clip: 0.1557 - val_loss: 0.0400 - val_masked_rmse_clip: 0.1607\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - masked_rmse_clip: 0.1557 - val_loss: 0.0399 - val_masked_rmse_clip: 0.1608\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0382 - masked_rmse_clip: 0.1561 - val_loss: 0.0399 - val_masked_rmse_clip: 0.1605\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - masked_rmse_clip: 0.1553 - val_loss: 0.0397 - val_masked_rmse_clip: 0.1603\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - masked_rmse_clip: 0.1549 - val_loss: 0.0398 - val_masked_rmse_clip: 0.1602\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - masked_rmse_clip: 0.1565 - val_loss: 0.0398 - val_masked_rmse_clip: 0.1602\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0380 - masked_rmse_clip: 0.1553 - val_loss: 0.0396 - val_masked_rmse_clip: 0.1600\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0379 - masked_rmse_clip: 0.1552 - val_loss: 0.0396 - val_masked_rmse_clip: 0.1599\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0379 - masked_rmse_clip: 0.1550 - val_loss: 0.0396 - val_masked_rmse_clip: 0.1599\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - masked_rmse_clip: 0.1548 - val_loss: 0.0395 - val_masked_rmse_clip: 0.1598\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0378 - masked_rmse_clip: 0.1539 - val_loss: 0.0395 - val_masked_rmse_clip: 0.1596\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - masked_rmse_clip: 0.1546 - val_loss: 0.0394 - val_masked_rmse_clip: 0.1596\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0377 - masked_rmse_clip: 0.1554 - val_loss: 0.0393 - val_masked_rmse_clip: 0.1594\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - masked_rmse_clip: 0.1539 - val_loss: 0.0393 - val_masked_rmse_clip: 0.1594\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0376 - masked_rmse_clip: 0.1550 - val_loss: 0.0393 - val_masked_rmse_clip: 0.1592\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - masked_rmse_clip: 0.1542 - val_loss: 0.0392 - val_masked_rmse_clip: 0.1592\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0375 - masked_rmse_clip: 0.1537 - val_loss: 0.0392 - val_masked_rmse_clip: 0.1590\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - masked_rmse_clip: 0.1552 - val_loss: 0.0390 - val_masked_rmse_clip: 0.1590\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0374 - masked_rmse_clip: 0.1539 - val_loss: 0.0390 - val_masked_rmse_clip: 0.1588\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - masked_rmse_clip: 0.1538 - val_loss: 0.0390 - val_masked_rmse_clip: 0.1587\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0373 - masked_rmse_clip: 0.1540 - val_loss: 0.0390 - val_masked_rmse_clip: 0.1586\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - masked_rmse_clip: 0.1532 - val_loss: 0.0389 - val_masked_rmse_clip: 0.1585\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0372 - masked_rmse_clip: 0.1535 - val_loss: 0.0389 - val_masked_rmse_clip: 0.1584\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0371 - masked_rmse_clip: 0.1542 - val_loss: 0.0388 - val_masked_rmse_clip: 0.1583\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0371 - masked_rmse_clip: 0.1533 - val_loss: 0.0387 - val_masked_rmse_clip: 0.1582\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0370 - masked_rmse_clip: 0.1533 - val_loss: 0.0387 - val_masked_rmse_clip: 0.1581\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0370 - masked_rmse_clip: 0.1536 - val_loss: 0.0387 - val_masked_rmse_clip: 0.1580\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - masked_rmse_clip: 0.1532 - val_loss: 0.0386 - val_masked_rmse_clip: 0.1579\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0369 - masked_rmse_clip: 0.1531 - val_loss: 0.0386 - val_masked_rmse_clip: 0.1578\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - masked_rmse_clip: 0.1527 - val_loss: 0.0385 - val_masked_rmse_clip: 0.1577\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0368 - masked_rmse_clip: 0.1520 - val_loss: 0.0385 - val_masked_rmse_clip: 0.1576\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - masked_rmse_clip: 0.1528 - val_loss: 0.0384 - val_masked_rmse_clip: 0.1575\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - masked_rmse_clip: 0.1525 - val_loss: 0.0384 - val_masked_rmse_clip: 0.1574\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0367 - masked_rmse_clip: 0.1521 - val_loss: 0.0383 - val_masked_rmse_clip: 0.1572\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - masked_rmse_clip: 0.1530 - val_loss: 0.0382 - val_masked_rmse_clip: 0.1572\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0366 - masked_rmse_clip: 0.1525 - val_loss: 0.0382 - val_masked_rmse_clip: 0.1571\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - masked_rmse_clip: 0.1516 - val_loss: 0.0382 - val_masked_rmse_clip: 0.1570\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0365 - masked_rmse_clip: 0.1524 - val_loss: 0.0381 - val_masked_rmse_clip: 0.1569\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - masked_rmse_clip: 0.1511 - val_loss: 0.0380 - val_masked_rmse_clip: 0.1568\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0364 - masked_rmse_clip: 0.1522 - val_loss: 0.0380 - val_masked_rmse_clip: 0.1567\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0363 - masked_rmse_clip: 0.1522 - val_loss: 0.0380 - val_masked_rmse_clip: 0.1567\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0363 - masked_rmse_clip: 0.1519 - val_loss: 0.0379 - val_masked_rmse_clip: 0.1566\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - masked_rmse_clip: 0.1515 - val_loss: 0.0379 - val_masked_rmse_clip: 0.1564\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0362 - masked_rmse_clip: 0.1524 - val_loss: 0.0378 - val_masked_rmse_clip: 0.1563\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - masked_rmse_clip: 0.1506 - val_loss: 0.0377 - val_masked_rmse_clip: 0.1562\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0361 - masked_rmse_clip: 0.1516 - val_loss: 0.0379 - val_masked_rmse_clip: 0.1562\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - masked_rmse_clip: 0.1510 - val_loss: 0.0377 - val_masked_rmse_clip: 0.1560\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - masked_rmse_clip: 0.1518 - val_loss: 0.0377 - val_masked_rmse_clip: 0.1558\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0360 - masked_rmse_clip: 0.1503 - val_loss: 0.0375 - val_masked_rmse_clip: 0.1559\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - masked_rmse_clip: 0.1510 - val_loss: 0.0375 - val_masked_rmse_clip: 0.1558\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0359 - masked_rmse_clip: 0.1507 - val_loss: 0.0375 - val_masked_rmse_clip: 0.1556\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - masked_rmse_clip: 0.1506 - val_loss: 0.0374 - val_masked_rmse_clip: 0.1556\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0358 - masked_rmse_clip: 0.1501 - val_loss: 0.0375 - val_masked_rmse_clip: 0.1555\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - masked_rmse_clip: 0.1507 - val_loss: 0.0374 - val_masked_rmse_clip: 0.1553\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0357 - masked_rmse_clip: 0.1505 - val_loss: 0.0372 - val_masked_rmse_clip: 0.1553\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0356 - masked_rmse_clip: 0.1505 - val_loss: 0.0372 - val_masked_rmse_clip: 0.1550\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0356 - masked_rmse_clip: 0.1503 - val_loss: 0.0372 - val_masked_rmse_clip: 0.1550\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - masked_rmse_clip: 0.1501 - val_loss: 0.0371 - val_masked_rmse_clip: 0.1549\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - masked_rmse_clip: 0.1504 - val_loss: 0.0371 - val_masked_rmse_clip: 0.1548\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0355 - masked_rmse_clip: 0.1498 - val_loss: 0.0371 - val_masked_rmse_clip: 0.1548\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - masked_rmse_clip: 0.1491 - val_loss: 0.0370 - val_masked_rmse_clip: 0.1547\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0354 - masked_rmse_clip: 0.1503 - val_loss: 0.0369 - val_masked_rmse_clip: 0.1545\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - masked_rmse_clip: 0.1492 - val_loss: 0.0370 - val_masked_rmse_clip: 0.1545\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0353 - masked_rmse_clip: 0.1497 - val_loss: 0.0368 - val_masked_rmse_clip: 0.1543\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - masked_rmse_clip: 0.1491 - val_loss: 0.0369 - val_masked_rmse_clip: 0.1543\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0352 - masked_rmse_clip: 0.1491 - val_loss: 0.0367 - val_masked_rmse_clip: 0.1542\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - masked_rmse_clip: 0.1493 - val_loss: 0.0367 - val_masked_rmse_clip: 0.1541\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - masked_rmse_clip: 0.1493 - val_loss: 0.0367 - val_masked_rmse_clip: 0.1540\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0351 - masked_rmse_clip: 0.1487 - val_loss: 0.0367 - val_masked_rmse_clip: 0.1539\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0350 - masked_rmse_clip: 0.1487 - val_loss: 0.0367 - val_masked_rmse_clip: 0.1538\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0350 - masked_rmse_clip: 0.1490 - val_loss: 0.0365 - val_masked_rmse_clip: 0.1537\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - masked_rmse_clip: 0.1489 - val_loss: 0.0364 - val_masked_rmse_clip: 0.1536\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0349 - masked_rmse_clip: 0.1490 - val_loss: 0.0364 - val_masked_rmse_clip: 0.1535\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - masked_rmse_clip: 0.1486 - val_loss: 0.0364 - val_masked_rmse_clip: 0.1535\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - masked_rmse_clip: 0.1487 - val_loss: 0.0364 - val_masked_rmse_clip: 0.1534\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0348 - masked_rmse_clip: 0.1485 - val_loss: 0.0363 - val_masked_rmse_clip: 0.1533\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - masked_rmse_clip: 0.1483 - val_loss: 0.0363 - val_masked_rmse_clip: 0.1532\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0347 - masked_rmse_clip: 0.1485 - val_loss: 0.0363 - val_masked_rmse_clip: 0.1531\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - masked_rmse_clip: 0.1485 - val_loss: 0.0362 - val_masked_rmse_clip: 0.1529\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0346 - masked_rmse_clip: 0.1482 - val_loss: 0.0361 - val_masked_rmse_clip: 0.1528\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - masked_rmse_clip: 0.1475 - val_loss: 0.0361 - val_masked_rmse_clip: 0.1527\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - masked_rmse_clip: 0.1479 - val_loss: 0.0360 - val_masked_rmse_clip: 0.1526\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0345 - masked_rmse_clip: 0.1473 - val_loss: 0.0360 - val_masked_rmse_clip: 0.1525\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - masked_rmse_clip: 0.1483 - val_loss: 0.0359 - val_masked_rmse_clip: 0.1525\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0344 - masked_rmse_clip: 0.1464 - val_loss: 0.0359 - val_masked_rmse_clip: 0.1523\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0343 - masked_rmse_clip: 0.1470 - val_loss: 0.0359 - val_masked_rmse_clip: 0.1523\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0343 - masked_rmse_clip: 0.1475 - val_loss: 0.0358 - val_masked_rmse_clip: 0.1522\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - masked_rmse_clip: 0.1481 - val_loss: 0.0358 - val_masked_rmse_clip: 0.1523\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - masked_rmse_clip: 0.1466 - val_loss: 0.0357 - val_masked_rmse_clip: 0.1521\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0342 - masked_rmse_clip: 0.1471 - val_loss: 0.0357 - val_masked_rmse_clip: 0.1519\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - masked_rmse_clip: 0.1472 - val_loss: 0.0356 - val_masked_rmse_clip: 0.1517\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0341 - masked_rmse_clip: 0.1471 - val_loss: 0.0355 - val_masked_rmse_clip: 0.1517\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - masked_rmse_clip: 0.1470 - val_loss: 0.0355 - val_masked_rmse_clip: 0.1517\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0340 - masked_rmse_clip: 0.1470 - val_loss: 0.0355 - val_masked_rmse_clip: 0.1516\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - masked_rmse_clip: 0.1468 - val_loss: 0.0355 - val_masked_rmse_clip: 0.1514\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - masked_rmse_clip: 0.1464 - val_loss: 0.0354 - val_masked_rmse_clip: 0.1514\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0339 - masked_rmse_clip: 0.1471 - val_loss: 0.0353 - val_masked_rmse_clip: 0.1512\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - masked_rmse_clip: 0.1456 - val_loss: 0.0354 - val_masked_rmse_clip: 0.1511\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0338 - masked_rmse_clip: 0.1460 - val_loss: 0.0354 - val_masked_rmse_clip: 0.1511\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - masked_rmse_clip: 0.1468 - val_loss: 0.0352 - val_masked_rmse_clip: 0.1510\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0337 - masked_rmse_clip: 0.1463 - val_loss: 0.0352 - val_masked_rmse_clip: 0.1509\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0337 - masked_rmse_clip: 0.1458 - val_loss: 0.0352 - val_masked_rmse_clip: 0.1508\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - masked_rmse_clip: 0.1456 - val_loss: 0.0351 - val_masked_rmse_clip: 0.1508\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0336 - masked_rmse_clip: 0.1456 - val_loss: 0.0351 - val_masked_rmse_clip: 0.1506\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - masked_rmse_clip: 0.1453 - val_loss: 0.0350 - val_masked_rmse_clip: 0.1506\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - masked_rmse_clip: 0.1455 - val_loss: 0.0350 - val_masked_rmse_clip: 0.1505\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0335 - masked_rmse_clip: 0.1466 - val_loss: 0.0350 - val_masked_rmse_clip: 0.1504\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - masked_rmse_clip: 0.1462 - val_loss: 0.0349 - val_masked_rmse_clip: 0.1503\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0334 - masked_rmse_clip: 0.1460 - val_loss: 0.0348 - val_masked_rmse_clip: 0.1502\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - masked_rmse_clip: 0.1448 - val_loss: 0.0348 - val_masked_rmse_clip: 0.1500\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0333 - masked_rmse_clip: 0.1455 - val_loss: 0.0347 - val_masked_rmse_clip: 0.1500\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - masked_rmse_clip: 0.1457 - val_loss: 0.0347 - val_masked_rmse_clip: 0.1501\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0332 - masked_rmse_clip: 0.1448 - val_loss: 0.0347 - val_masked_rmse_clip: 0.1499\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0332 - masked_rmse_clip: 0.1446 - val_loss: 0.0347 - val_masked_rmse_clip: 0.1498\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - masked_rmse_clip: 0.1452 - val_loss: 0.0346 - val_masked_rmse_clip: 0.1497\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - masked_rmse_clip: 0.1448 - val_loss: 0.0346 - val_masked_rmse_clip: 0.1497\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0331 - masked_rmse_clip: 0.1454 - val_loss: 0.0345 - val_masked_rmse_clip: 0.1495\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - masked_rmse_clip: 0.1454 - val_loss: 0.0344 - val_masked_rmse_clip: 0.1494\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0330 - masked_rmse_clip: 0.1447 - val_loss: 0.0344 - val_masked_rmse_clip: 0.1493\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0329 - masked_rmse_clip: 0.1430 - val_loss: 0.0344 - val_masked_rmse_clip: 0.1492\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - masked_rmse_clip: 0.1453 - val_loss: 0.0344 - val_masked_rmse_clip: 0.1491\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0329 - masked_rmse_clip: 0.1436 - val_loss: 0.0343 - val_masked_rmse_clip: 0.1490\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - masked_rmse_clip: 0.1444 - val_loss: 0.0343 - val_masked_rmse_clip: 0.1489\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0328 - masked_rmse_clip: 0.1452 - val_loss: 0.0344 - val_masked_rmse_clip: 0.1489\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - masked_rmse_clip: 0.1433 - val_loss: 0.0342 - val_masked_rmse_clip: 0.1487\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - masked_rmse_clip: 0.1438 - val_loss: 0.0341 - val_masked_rmse_clip: 0.1486\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0327 - masked_rmse_clip: 0.1438 - val_loss: 0.0341 - val_masked_rmse_clip: 0.1486\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - masked_rmse_clip: 0.1452 - val_loss: 0.0340 - val_masked_rmse_clip: 0.1486\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0326 - masked_rmse_clip: 0.1437 - val_loss: 0.0340 - val_masked_rmse_clip: 0.1484\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - masked_rmse_clip: 0.1433 - val_loss: 0.0340 - val_masked_rmse_clip: 0.1483\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - masked_rmse_clip: 0.1434 - val_loss: 0.0340 - val_masked_rmse_clip: 0.1483\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0325 - masked_rmse_clip: 0.1425 - val_loss: 0.0339 - val_masked_rmse_clip: 0.1482\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - masked_rmse_clip: 0.1441 - val_loss: 0.0338 - val_masked_rmse_clip: 0.1480\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0324 - masked_rmse_clip: 0.1431 - val_loss: 0.0338 - val_masked_rmse_clip: 0.1480\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0324 - masked_rmse_clip: 0.1434 - val_loss: 0.0338 - val_masked_rmse_clip: 0.1479\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - masked_rmse_clip: 0.1424 - val_loss: 0.0338 - val_masked_rmse_clip: 0.1479\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0323 - masked_rmse_clip: 0.1433 - val_loss: 0.0337 - val_masked_rmse_clip: 0.1477\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - masked_rmse_clip: 0.1436 - val_loss: 0.0338 - val_masked_rmse_clip: 0.1477\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - masked_rmse_clip: 0.1440 - val_loss: 0.0336 - val_masked_rmse_clip: 0.1475\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0322 - masked_rmse_clip: 0.1439 - val_loss: 0.0336 - val_masked_rmse_clip: 0.1475\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - masked_rmse_clip: 0.1422 - val_loss: 0.0336 - val_masked_rmse_clip: 0.1474\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0321 - masked_rmse_clip: 0.1419 - val_loss: 0.0335 - val_masked_rmse_clip: 0.1474\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0321 - masked_rmse_clip: 0.1428 - val_loss: 0.0336 - val_masked_rmse_clip: 0.1473\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - masked_rmse_clip: 0.1430 - val_loss: 0.0335 - val_masked_rmse_clip: 0.1471\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0320 - masked_rmse_clip: 0.1430 - val_loss: 0.0334 - val_masked_rmse_clip: 0.1471\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - masked_rmse_clip: 0.1415 - val_loss: 0.0333 - val_masked_rmse_clip: 0.1471\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - masked_rmse_clip: 0.1414 - val_loss: 0.0333 - val_masked_rmse_clip: 0.1470\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0319 - masked_rmse_clip: 0.1416 - val_loss: 0.0333 - val_masked_rmse_clip: 0.1469\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0318 - masked_rmse_clip: 0.1422 - val_loss: 0.0332 - val_masked_rmse_clip: 0.1469\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - masked_rmse_clip: 0.1426 - val_loss: 0.0332 - val_masked_rmse_clip: 0.1467\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0318 - masked_rmse_clip: 0.1419 - val_loss: 0.0332 - val_masked_rmse_clip: 0.1466\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - masked_rmse_clip: 0.1417 - val_loss: 0.0331 - val_masked_rmse_clip: 0.1465\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - masked_rmse_clip: 0.1409 - val_loss: 0.0331 - val_masked_rmse_clip: 0.1465\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0317 - masked_rmse_clip: 0.1421 - val_loss: 0.0330 - val_masked_rmse_clip: 0.1463\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - masked_rmse_clip: 0.1414 - val_loss: 0.0330 - val_masked_rmse_clip: 0.1463\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0316 - masked_rmse_clip: 0.1424 - val_loss: 0.0330 - val_masked_rmse_clip: 0.1462\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - masked_rmse_clip: 0.1412 - val_loss: 0.0330 - val_masked_rmse_clip: 0.1461\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - masked_rmse_clip: 0.1425 - val_loss: 0.0329 - val_masked_rmse_clip: 0.1460\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0315 - masked_rmse_clip: 0.1422 - val_loss: 0.0328 - val_masked_rmse_clip: 0.1461\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - masked_rmse_clip: 0.1415 - val_loss: 0.0329 - val_masked_rmse_clip: 0.1459\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - masked_rmse_clip: 0.1408 - val_loss: 0.0328 - val_masked_rmse_clip: 0.1459\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0314 - masked_rmse_clip: 0.1410 - val_loss: 0.0327 - val_masked_rmse_clip: 0.1457\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0313 - masked_rmse_clip: 0.1409 - val_loss: 0.0328 - val_masked_rmse_clip: 0.1457\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - masked_rmse_clip: 0.1413 - val_loss: 0.0327 - val_masked_rmse_clip: 0.1456\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0313 - masked_rmse_clip: 0.1411 - val_loss: 0.0326 - val_masked_rmse_clip: 0.1455\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0312 - masked_rmse_clip: 0.1409 - val_loss: 0.0327 - val_masked_rmse_clip: 0.1454\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0312 - masked_rmse_clip: 0.1403 - val_loss: 0.0326 - val_masked_rmse_clip: 0.1452\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - masked_rmse_clip: 0.1394 - val_loss: 0.0325 - val_masked_rmse_clip: 0.1452\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - masked_rmse_clip: 0.1405 - val_loss: 0.0325 - val_masked_rmse_clip: 0.1452\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0311 - masked_rmse_clip: 0.1399 - val_loss: 0.0325 - val_masked_rmse_clip: 0.1452\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - masked_rmse_clip: 0.1407 - val_loss: 0.0324 - val_masked_rmse_clip: 0.1450\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0310 - masked_rmse_clip: 0.1406 - val_loss: 0.0324 - val_masked_rmse_clip: 0.1450\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0310 - masked_rmse_clip: 0.1405 - val_loss: 0.0323 - val_masked_rmse_clip: 0.1449\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - masked_rmse_clip: 0.1405 - val_loss: 0.0325 - val_masked_rmse_clip: 0.1449\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - masked_rmse_clip: 0.1400 - val_loss: 0.0323 - val_masked_rmse_clip: 0.1447\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0309 - masked_rmse_clip: 0.1403 - val_loss: 0.0322 - val_masked_rmse_clip: 0.1448\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0308 - masked_rmse_clip: 0.1408 - val_loss: 0.0323 - val_masked_rmse_clip: 0.1446\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - masked_rmse_clip: 0.1401 - val_loss: 0.0322 - val_masked_rmse_clip: 0.1445\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0308 - masked_rmse_clip: 0.1390 - val_loss: 0.0321 - val_masked_rmse_clip: 0.1444\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - masked_rmse_clip: 0.1393 - val_loss: 0.0321 - val_masked_rmse_clip: 0.1443\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - masked_rmse_clip: 0.1400 - val_loss: 0.0321 - val_masked_rmse_clip: 0.1442\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0307 - masked_rmse_clip: 0.1400 - val_loss: 0.0320 - val_masked_rmse_clip: 0.1442\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - masked_rmse_clip: 0.1397 - val_loss: 0.0320 - val_masked_rmse_clip: 0.1441\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - masked_rmse_clip: 0.1404 - val_loss: 0.0320 - val_masked_rmse_clip: 0.1441\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0306 - masked_rmse_clip: 0.1393 - val_loss: 0.0320 - val_masked_rmse_clip: 0.1439\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - masked_rmse_clip: 0.1394 - val_loss: 0.0319 - val_masked_rmse_clip: 0.1439\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - masked_rmse_clip: 0.1394 - val_loss: 0.0319 - val_masked_rmse_clip: 0.1438\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0305 - masked_rmse_clip: 0.1390 - val_loss: 0.0318 - val_masked_rmse_clip: 0.1437\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - masked_rmse_clip: 0.1394 - val_loss: 0.0319 - val_masked_rmse_clip: 0.1437\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0304 - masked_rmse_clip: 0.1381 - val_loss: 0.0318 - val_masked_rmse_clip: 0.1436\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - masked_rmse_clip: 0.1387 - val_loss: 0.0317 - val_masked_rmse_clip: 0.1435\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - masked_rmse_clip: 0.1391 - val_loss: 0.0316 - val_masked_rmse_clip: 0.1434\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - masked_rmse_clip: 0.1395 - val_loss: 0.0317 - val_masked_rmse_clip: 0.1434\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0303 - masked_rmse_clip: 0.1395 - val_loss: 0.0315 - val_masked_rmse_clip: 0.1433\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - masked_rmse_clip: 0.1380 - val_loss: 0.0315 - val_masked_rmse_clip: 0.1432\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - masked_rmse_clip: 0.1389 - val_loss: 0.0317 - val_masked_rmse_clip: 0.1432\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0302 - masked_rmse_clip: 0.1381 - val_loss: 0.0315 - val_masked_rmse_clip: 0.1431\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - masked_rmse_clip: 0.1384 - val_loss: 0.0315 - val_masked_rmse_clip: 0.1430\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - masked_rmse_clip: 0.1385 - val_loss: 0.0314 - val_masked_rmse_clip: 0.1429\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0301 - masked_rmse_clip: 0.1378 - val_loss: 0.0315 - val_masked_rmse_clip: 0.1429\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - masked_rmse_clip: 0.1384 - val_loss: 0.0314 - val_masked_rmse_clip: 0.1428\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0300 - masked_rmse_clip: 0.1375 - val_loss: 0.0313 - val_masked_rmse_clip: 0.1427\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0300 - masked_rmse_clip: 0.1381 - val_loss: 0.0313 - val_masked_rmse_clip: 0.1426\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - masked_rmse_clip: 0.1379 - val_loss: 0.0313 - val_masked_rmse_clip: 0.1426\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - masked_rmse_clip: 0.1381 - val_loss: 0.0312 - val_masked_rmse_clip: 0.1425\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0299 - masked_rmse_clip: 0.1376 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1424\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - masked_rmse_clip: 0.1389 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1423\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0298 - masked_rmse_clip: 0.1377 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1423\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - masked_rmse_clip: 0.1370 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1421\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0298 - masked_rmse_clip: 0.1374 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1421\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - masked_rmse_clip: 0.1375 - val_loss: 0.0311 - val_masked_rmse_clip: 0.1420\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0297 - masked_rmse_clip: 0.1373 - val_loss: 0.0310 - val_masked_rmse_clip: 0.1419\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - masked_rmse_clip: 0.1380 - val_loss: 0.0310 - val_masked_rmse_clip: 0.1419\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - masked_rmse_clip: 0.1372 - val_loss: 0.0310 - val_masked_rmse_clip: 0.1418\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0296 - masked_rmse_clip: 0.1365 - val_loss: 0.0309 - val_masked_rmse_clip: 0.1418\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0296 - masked_rmse_clip: 0.1368 - val_loss: 0.0309 - val_masked_rmse_clip: 0.1417\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - masked_rmse_clip: 0.1367 - val_loss: 0.0309 - val_masked_rmse_clip: 0.1416\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0295 - masked_rmse_clip: 0.1371 - val_loss: 0.0308 - val_masked_rmse_clip: 0.1415\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0295 - masked_rmse_clip: 0.1367 - val_loss: 0.0308 - val_masked_rmse_clip: 0.1415\n"
     ]
    }
   ],
   "source": [
    "early_stopping_callback = keras.callbacks.EarlyStopping(patience=patience,restore_best_weights=True)\n",
    "hist = model.fit(train_data, train_data, batch_size=batch_size, epochs=epochs, \n",
    "                    validation_data=(test_data, test_data), callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Learning Curves\n",
    "\n",
    "plt.plot(hist.history['masked_rmse_clip'], label=\"train\")\n",
    "plt.plot(hist.history['val_masked_rmse_clip'], label=\"valid\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Masked rmse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "V7VSmc5O0ew1"
   ],
   "name": "DeepAE_Rec.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "moontorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
